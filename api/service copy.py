#!/usr/bin/env python
# -*- encoding: utf-8 -*-
"""
@File    :   service.py
@Time    :   2023/05/22 12:13:32
@Author  :   Li Ruilong
@Version :   1.0
@Contact :   liruilonger@gmail.com
@Desc    :   
"""

# here put the import lib

import cv2
import imutils
from deepface import DeepFace
from decimal import Decimal
from imutils import paths
import os
import units 
import copy



def extract_faces_all(image, detector_backend='retinaface', align=True):
    """
    @Time    :   2023/05/20 03:50:07
    @Author  :   liruilonger@gmail.com
    @Version :   1.0
    @Desc    :   extract_faces ç”¨äºå¯¹å›¾åƒè¿›è¡Œç‰¹å¾åˆ†æï¼Œæå–å¤´åƒåæ ‡ï¼Œ
                    åœ¨å®é™…ä½¿ç”¨ä¸­ï¼Œå¦‚æœå¯¹ç²¾åº¦æœ‰è¦æ±‚ï¼Œå¯ä»¥é€šè¿‡ `confidence` æ¥å¯¹æå–çš„äººè„¸è¿›è¡Œè¿‡æ»¤ï¼Œ
                 Args:
                 extract_facesæ–¹æ³•æ¥å—ä»¥ä¸‹å‚æ•°ï¼š
                    - img_pathï¼šè¦ä»ä¸­æå–äººè„¸çš„å›¾åƒè·¯å¾„ã€numpyæ•°ç»„ï¼ˆBGRï¼‰æˆ–base64ç¼–ç çš„å›¾åƒã€‚
                    - target_sizeï¼šäººè„¸å›¾åƒçš„æœ€ç»ˆå½¢çŠ¶ã€‚å°†æ·»åŠ é»‘è‰²åƒç´ ä»¥è°ƒæ•´å›¾åƒå¤§å°ã€‚
                    - detector_backendï¼šäººè„¸æ£€æµ‹åç«¯å¯ä»¥æ˜¯retinafaceã€mtcnnã€opencvã€ssdæˆ–dlibã€‚
                    - enforce_detectionï¼šå¦‚æœåœ¨æä¾›çš„å›¾åƒä¸­æ— æ³•æ£€æµ‹åˆ°äººè„¸ï¼Œåˆ™è¯¥å‡½æ•°ä¼šå¼•å‘å¼‚å¸¸ã€‚å¦‚æœä¸æƒ³å¾—åˆ°å¼‚å¸¸å¹¶ä»è¦è¿è¡Œè¯¥å‡½æ•°ï¼Œåˆ™å°†å…¶è®¾ç½®ä¸ºFalseã€‚
                    - alignï¼šæ ¹æ®çœ¼ç›ä½ç½®å¯¹é½ã€‚
                    - grayscaleï¼šä»¥RGBæˆ–ç°åº¦æå–äººè„¸ã€‚

                 Returns:
                   è¿”å›ä¸€ä¸ªåŒ…å«äººè„¸å›¾åƒã€äººè„¸åŒºåŸŸå’Œç½®ä¿¡åº¦çš„å­—å…¸åˆ—è¡¨ã€‚å…¶ä¸­ï¼Œ
                   - face é”®å¯¹åº”çš„å€¼æ˜¯æå–çš„äººè„¸å›¾åƒ
                   - facial_area é”®å¯¹åº”çš„å€¼æ˜¯äººè„¸åœ¨åŸå§‹å›¾åƒä¸­çš„ä½ç½®å’Œå¤§å°
                   - confidence é”®å¯¹åº”çš„å€¼æ˜¯äººè„¸æ£€æµ‹çš„ç½®ä¿¡åº¦

    """
    # img_path = "huge_1.jpg"

    # è¯»å–åŸå§‹å›¾åƒ
    rst = None
    try:
        rst = DeepFace.extract_faces(
            img_path=image,
            target_size=(224, 224),
            detector_backend="mtcnn",
            enforce_detection=True,
            align=True,
            grayscale=False)
    except Exception as e:
        print(e)
        return

    # print(rst)
    # äººè„¸åæ ‡å’Œç½®ä¿¡åº¦
    to_deepfaces = []
    image_no_mark = copy.deepcopy(image)
    for i, f in enumerate(rst):
        # print(i, f)
        #         print('ğŸ˜Š'.rjust(i * 2, 'ğŸ˜Š'))
        print("ç¼–å·ï¼š", i, '\n', " æ£€æµ‹äººè„¸ä½ç½®:", f['facial_area'], '\n', " ç½®ä¿¡åº¦:", f['confidence'])
        x, y, w, h = f['facial_area'].values()
        x1, y1, x2, y2 = x, y, x + w, y + h
        # æ ¹æ®ä¸åŒçš„ç½®ä¿¡åº¦åšä¸åŒæ ‡è®°
        confidence = Decimal(str(f['confidence']))
        best = Decimal('1')
        color = (0, 255, 0)

        abs_ = best - confidence
        if 0.01 <= abs_ < 0.05:
            color = (255, 0, 255)
        elif 0.08 > abs_ >= 0.05:
            color = (0, 165, 255)
        elif abs_ >= 0.08:
            color = (255, 255, 255)
        else:
            pass
            # è¿™ä¸ªç²¾åº¦çš„è€ƒè™‘ç”¨äºè¯†åˆ«
        cropped_img = image_no_mark[y:y + h, x:x + w]
         #å¯¹åˆ‡ç‰‡è¿›è¡Œç­‰æ¯”æ”¾å¤§
        cropped_img = imutils.resize(cropped_img, width=400)
        #cv2.imwrite('new_' + str(i) + img_path, cropped_img)
        img_c =  units.get_img_to_base64(cropped_img)
        to_deepfaces.append({"facial_area":f['facial_area'],"confidence":format(f['confidence'], '0.4f'),"img_b64":img_c})

        # æ ¹æ®åæ ‡æ ‡è®°å›¾ç‰‡,æ ‡è®°æ¡†çš„å·¦ä¸Šè§’å’Œå³ä¸‹è§’çš„åæ ‡,
        cv2.rectangle(image, (x1, y1), (x2, y2), color, 1)
        # æ·»åŠ  ç½®ä¿¡åº¦æ ‡ç­¾
        cv2.putText(image, format(f['confidence'], '0.4f'), (x1, y1 - 5), cv2.FONT_HERSHEY_COMPLEX, 0.5, color, 1,
                    cv2.LINE_4)
    return image,rst,to_deepfaces
        


def represent(img_path, model_name, detector_backend, enforce_detection, align):
    """
    @Time    :   2023/05/22 12:11:58
    @Author  :   liruilonger@gmail.com
    @Version :   1.0
    @Desc    :   None
                 Args:
                   
                 Returns:
                   void
    """
    result = {}
    embedding_objs = DeepFace.represent(
        img_path=img_path,
        model_name=model_name,
        detector_backend=detector_backend,
        enforce_detection=enforce_detection,
        align=align,
    )
    result["results"] = embedding_objs
    return result


def verify(
    img1_path, img2_path, model_name, detector_backend, distance_metric, enforce_detection, align
):
    obj = DeepFace.verify(
        img1_path=img1_path,
        img2_path=img2_path,
        model_name=model_name,
        detector_backend=detector_backend,
        distance_metric=distance_metric,
        align=align,
        enforce_detection=enforce_detection,
    )
    return obj


def analyze(image, actions, detector_backend, enforce_detection, align):
    """
    @Time    :   2023/05/30 23:53:42
    @Author  :   liruilonger@gmail.com
    @Version :   1.0
    @Desc    :   analyze æ–¹æ³•æ˜¯ DeepFace åº“ä¸­çš„ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºåˆ†æäººè„¸å±æ€§ï¼ŒåŒ…æ‹¬å¹´é¾„ã€æ€§åˆ«ã€æƒ…ç»ªå’Œç§æ—ã€‚
                 åœ¨åå°ï¼Œåˆ†æå‡½æ•°æ„å»ºå·ç§¯ç¥ç»ç½‘ç»œæ¨¡å‹ï¼Œä»¥å¯¹è¾“å…¥å›¾åƒä¸­çš„äººè„¸è¿›è¡Œå¹´é¾„ã€æ€§åˆ«ã€æƒ…ç»ªå’Œç§æ—åˆ†ç±»ã€‚
                 Args:
                   - img_path:å›¾åƒè·¯å¾„ã€numpy æ•°ç»„ï¼ˆBGRï¼‰æˆ– base64 ç¼–ç çš„å›¾åƒã€‚å¦‚æœæºå›¾åƒä¸­æœ‰å¤šä¸ªäººè„¸ï¼Œåˆ™ç»“æœå°†æ˜¯å‡ºç°åœ¨å›¾åƒä¸­çš„äººè„¸æ•°é‡å¤§å°çš„åˆ—è¡¨ã€‚
                   - actions: å‚æ•°æ˜¯ä¸€ä¸ªå…ƒç»„ï¼Œå…¶ä¸­é»˜è®¤å€¼ä¸º ('age', 'gender', 'emotion', 'race')ï¼Œæ‚¨å¯ä»¥åˆ é™¤å…¶ä¸­çš„ä¸€äº›å±æ€§ã€‚
                   - enforce_detection :å‚æ•°é»˜è®¤ä¸º Trueï¼Œå¦‚æœæœªæ£€æµ‹åˆ°äººè„¸ï¼Œåˆ™å‡½æ•°ä¼šæŠ›å‡ºå¼‚å¸¸ã€‚å¦‚æœæ‚¨ä¸æƒ³å¾—åˆ°å¼‚å¸¸ï¼Œåˆ™å¯ä»¥å°†å…¶è®¾ç½®ä¸º Falseã€‚è¿™å¯¹äºä½åˆ†è¾¨ç‡å›¾åƒå¯èƒ½å¾ˆæ–¹ä¾¿ã€‚
                   - detector_backend: å‚æ•°æŒ‡å®šè¦ä½¿ç”¨çš„äººè„¸æ£€æµ‹å™¨çš„åç«¯ï¼Œä¾‹å¦‚ OpenCVã€RetinaFaceã€MTCNN ç­‰ã€‚
                   - align: å‚æ•°æ˜¯ä¸€ä¸ªå¸ƒå°”å€¼ï¼Œè¡¨ç¤ºæ˜¯å¦æ ¹æ®çœ¼ç›ä½ç½®è¿›è¡Œå¯¹é½ã€‚
                   - silent :å‚æ•°æ˜¯ä¸€ä¸ªå¸ƒå°”å€¼ï¼Œè¡¨ç¤ºæ˜¯å¦ç¦ç”¨ï¼ˆæŸäº›ï¼‰æ—¥å¿—æ¶ˆæ¯ã€‚
                 Returns:
                    - "region"ï¼šè¡¨ç¤ºäººè„¸åœ¨å›¾åƒä¸­çš„ä½ç½®å’Œå¤§å°ã€‚
                    - "age"ï¼šè¡¨ç¤ºäººè„¸çš„å¹´é¾„ã€‚
                    - "dominant_gender"ï¼šè¡¨ç¤ºäººè„¸çš„ä¸»è¦æ€§åˆ«ã€‚
                    - "gender"ï¼šè¡¨ç¤ºäººè„¸çš„æ€§åˆ«åŠå…¶ç½®ä¿¡åº¦ã€‚
                    - "dominant_emotion"ï¼šè¡¨ç¤ºäººè„¸çš„ä¸»è¦æƒ…ç»ªã€‚
                    - "emotion"ï¼šè¡¨ç¤ºäººè„¸çš„æƒ…ç»ªåŠå…¶ç½®ä¿¡åº¦ã€‚
                    - "dominant_race"ï¼šè¡¨ç¤ºäººè„¸çš„ä¸»è¦ç§æ—ã€‚
                    - "race"ï¼šè¡¨ç¤ºäººè„¸çš„ç§æ—åŠå…¶ç½®ä¿¡åº¦ã€‚
    """
    result = None
    result =  DeepFace.analyze(
        img_path=image,
        actions=actions,
        detector_backend=detector_backend,
        enforce_detection=enforce_detection,
        align=align,
    )
    for f in  result:
        # print(i, f)
        #         print('ğŸ˜Š'.rjust(i * 2, 'ğŸ˜Š'))
        x, y, w, h = f['region'].values()
        x1, y1, x2, y2 = x, y, x + w, y + h
        # æ ¹æ®åæ ‡æ ‡è®°å›¾ç‰‡,æ ‡è®°æ¡†çš„å·¦ä¸Šè§’å’Œå³ä¸‹è§’çš„åæ ‡,
        cv2.rectangle(image, (x1, y1), (x2, y2),  (0, 255, 0), 1)
        # æ·»åŠ  ç½®ä¿¡åº¦æ ‡ç­¾

    
    return result,image

